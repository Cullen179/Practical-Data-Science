Implementation Plan â€” Task 1: Data Preparation (5%)

Dataset: student_data_25s3.csv
Source: Modified from the UCI Student Performance Dataset

1. Objective

The goal of this task is to prepare the dataset for subsequent analysis and modeling.
Specifically, we will:

Load and audit the student_data_25s3.csv file.

Identify and correct structural and semantic data issues (e.g., missing, inconsistent, or implausible values).

Produce a clean, well-typed, analysis-ready dataset.

This step constitutes the foundation for reproducible and valid insights in later tasks.

2. Context & Understanding

The dataset captures student demographic, social, and academic information and final performance outcomes.
Not all attributes from the UCI source are retained; hence, we must:

Cross-reference the subset of attributes in student_data_25s3.csv with the original UCI schema.

Interpret categorical encodings (e.g., "yes"/"no", "M"/"F") and confirm data types.

Validate numerical ranges for continuous attributes such as absences or grades.

3. Implementation Overview

All work will be conducted in a Jupyter Notebook (notebooks/data_preparation.ipynb) using Python 3.9+ with pandas, numpy, and matplotlib.

The notebook will follow these reproducible stages:

3.1 Setup

Import core libraries (pandas, numpy, matplotlib.pyplot, os).

Set display and reproducibility options (pd.set_option, random seed).

Define the file path constant (DATA_PATH = "data/student_data_25s3.csv").

3.2 Data Loading

Load the dataset using pd.read_csv(DATA_PATH).

Display basic structure: shape, columns, dtypes, and sample rows (head(), info()).

3.3 Structural Audit

Confirm data types against the attribute definitions (e.g., categorical vs numeric).

Detect parsing issues (string columns that should be numeric or categorical miscodings).

Identify duplicated rows (df.duplicated()).

3.4 Quality Checks

Missing Values: Quantify missingness per column and overall percentage.

Outliers & Range Violations:

Compare numeric variables (e.g., age, absences, G1/G2/G3) to logical or documented limits.

Flag and document out-of-range or implausible entries (e.g., negative study time).

Inconsistent Categoricals:

Normalize letter-case inconsistencies (e.g., yes vs Yes).

Validate known categories from UCI metadata.

3.5 Data Cleaning

Type Conversion:

Convert binary attributes (yes/no, M/F) to consistent categorical dtype.

Cast numeric columns (e.g., age, G1/G2/G3) to int or float as appropriate.

Missing Value Treatment:

Impute numeric fields using the median when appropriate.

Impute categorical fields using mode or logical substitution (e.g., "unknown").

Document every imputation rationale in code comments.

Deduplication:

Drop exact duplicates and verify record count after removal.

3.6 Exploratory Sanity Checks

Produce summary statistics (describe()).

Plot histograms for key numeric features (age, grades).

Plot frequency counts for major categorical attributes (school, study time, internet).

Verify that distributions appear plausible and that no structural corruption remains.